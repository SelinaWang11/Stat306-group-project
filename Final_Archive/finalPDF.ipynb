{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Final Project Report\n",
    "\n",
    "### STAT 306  \n",
    "### The University of British Columbia  \n",
    "### Yu Chang #47945050\n",
    "### Zhuoran Wang  \n",
    "\n",
    "</div>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "#### Background of Research\n",
    "The Chinese automobile company Geely Auto aims to enter the U.S. market by establishing a local manufacturing facility and producing cars domestically. Success in this market requires a comprehensive understanding of the specific factors that influence car prices in the U.S. By analyzing car features that American consumers value the most, Geely Auto can better align their product offerings with market expectations. This study focuses on analyzing car prices influenced by various factors using suitable multiple linear regression model to inform Geely Auto’s strategic decisions regarding feature selection and pricing.\n",
    "\n",
    "#### Motivation for Analysis\n",
    "he primary motivation for this study is to develop a multiple linear regression model that accurately estimates car prices based on their features. By understanding the relationship between various attributes and car prices, Geely Auto can tailor their production to match U.S. consumer preferences and ensure a competitive market entry. Additionally, the insights gained from this analysis can support feature selection and engineering for optimal pricing strategies.\n",
    "\n",
    "By employing a multiple linear regression model, this study aims to evaluate the strength and significance of relationships between car related features and price. The results will provide actionable insights into which features drive value in the eyes of U.S. consumers. This understanding is critical for guiding Geely Auto’s decisions on which features to prioritize in their designs, ensuring their products meet market expectations while remaining cost-effective.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Dataset Overview\n",
    "\n",
    "Given the context of the Chinese automobile company's will on sell cars in U.S. They have hired an automobile consulting firm to analyze the factors influencing car pricing. In particular, they aim to identify the key factors impacting car prices in the American market, as these may differ significantly from those in the Chinese market. \n",
    "\n",
    "The dataset was published in 2019. The exact timeframe and methodology of data collection is not declared on the source website. All features are measured in U.S. customary units, and all data points are from vehicles in the U.S based on various market surveys.The dataset has no missing values and no duplicate values, ensuring data quality for statistical inference purposes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is an entire overview of the variables recorded in the dataset: \n",
    "\n",
    "\n",
    "| Variable  | Type               | Description                                   | Unit          \n",
    "|-----------|--------------------|-----------------------------------------------|---------------|\n",
    "| car_ID | Categorical | the unique ID for the cars in the dataset | Unitless |\n",
    "| symboling | Categorical | the symbol for each car corresponds to the levels of the feature 'carbody' | Unitless\n",
    "| Carname | Categorical | the name of the car | Unitless | \n",
    "| fueltype  | Binary Categorical | The type of fuel the car uses: \"gas\" or \"diesel\" | Unitless |\n",
    "| aspiration  | Categorical | the type of aspiration used in the car's engine | Unitless\n",
    "| doornumber  | Categorical | the number of doors on the car | Unitless |\n",
    "| carbody | Categorical | The five different car category such as 'sedan','wagon' | Unitless |\n",
    "| drivewheel  | Cateogrical | the drive wheel type of car | Unitless\n",
    "| enginelocation | Categorical | the location of the engine in the car |Unitless|\n",
    "| wheelbase | Numerical | the distance between the front and rear axles of a vehicle  | inch|\n",
    "| carlength | Numerical | the length of the car | inch |\n",
    "|carwidth | Numerical | the width of the car | inch |\n",
    "|carheight | Numerical | the height of the car | inch |\n",
    "| curbweight | Numerical | total weight of the vehicle without passengers or cargo but includes all necessary operating fluids | lbs|\n",
    "| enginetype | Categorical|  type of engine used in the vehicles | Unitless\n",
    "| cylindernumber | Categorical | the number of cylinders in the car's engine |Unitless\n",
    " enginesize | Numerical | the size of the engine |  cubic inches |\n",
    " |fuelsystem | Categorical | fuel delivery system of the car | Unitless|\n",
    " |boreratio| Numerical |The ratio of the cylinder's bore to its stroke, affecting the engine's efficiency and power output | Unitless|\n",
    " |stroke| Numerical | The distance the piston travels inside the cylinder, impacting engine displacement and performance | inch |\n",
    " |compressionratio | Numerical |The ratio of the cylinder's maximum to minimum volume, influencing engine efficiency and power generation | Unitless |\n",
    "| horsepower | Numerical | the power of the engine |  hp |\n",
    "| peakrpm | Numerical | the engine's maximum revolution per minute at the peak power | peak revolutions per minute |\n",
    "| citympg | Numerical | the fuel efficiency in miles per gallon driving in city| miles per gallo |\n",
    "| highwaympg | Numerical | the fuel efficiency in miles per gallon driving in the highway| miles per gallo |\n",
    "|price | Numerical | the price of the car | US dollar |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis\n",
    "Present suitable visualizations of the data and a summary of any key features. Explain and apply the chosen statistical methodology to address the question(s) of interest motivating the study.\n",
    "\n",
    "\n",
    "\n",
    "### Preliminary Data Cleaning \n",
    "\n",
    "\n",
    "##### a.  Similar Representation\n",
    "\n",
    "The features **carlength**,” “**carwidth**,” “**carheight**,” “**curbweight**,” and “**wheelbase**” all represent attributes related to the size and dimensions of a car. Including all of these in the model would introduce redundancy and increase the complexity of the analysis. To address this, we select “**carlength**” as the most representative measure of car size. This decision is based on its straightforward interpretation and its expected relevance in determining car pricing. By dropping the remaining features, we reduce multicollinearity, simplify the model, and decrease the risk of overfitting.\n",
    "\n",
    "Similarly, the features “**citympg**” and “**highwaympg**” both describe the car’s fuel efficiency, but under different driving conditions. Since “**citympg**” is more reflective of real-world driving for most users, we choose to retain it while removing “**highwaympg**.” This reduces redundancy without losing critical information about fuel economy.\n",
    "\n",
    "For features such as “**fuelsystem**,” “**boreratio**,” “**stroke**,” “**compressionratio**,” “**enginetype**,” and **“horsepower,”** all are associated with the performance of the car’s engine. However, many of these features are technical and less intuitive to interpret for understanding car pricing. We retain “horsepower,” as it is a well-known and widely accepted metric for evaluating engine performance and has a clear impact on a car's value. The other features are excluded to streamline the analysis and improve the model's interpretability.\n",
    "\n",
    "\n",
    "#### b. Redundant Features\n",
    "\n",
    "The features **car_ID** is just representing the identical definition of the car in the dataset and **symboling** is just the numeric encoding of the feature \"**carbody**\". To simplify the mode, these features are excluded from the analysis.\n",
    "\n",
    "#### c. Complex Encoding\n",
    "\n",
    "The feature **CarName** is a text-based attribute. Encoding it as a categorical variable would be impractical due to the large number of unique values, which could result in an excessively complex model. In addition, encoding text feature as bag of words would lead to a spare wording matrix, which might underfit this feature and increase computational costs. Using advanced techniques like word vectors or transfer learning is beyond the scope of this analysis, so this feature is excluded for simplicity.\n",
    "\n",
    "#### d.Sparse Feature\n",
    "The categorical feature **\"car body\"** has too many unique levels. Given the small size of our dataset, the data points corresponding to each car body type are sparse. This sparsity may result in underrepresentation of certain car body types, leading to potential underfitting of the model. To simplify the model and improve its performance, we have decided to drop this feature.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Cleaning for Numerical Features\n",
    "\n",
    "Firstly, we take a look at the pre-cleaned data set to see what features are still there. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we plot the distributions of the numeric features left in the dataset to check the skewness.\n",
    "\n",
    "\n",
    "\n",
    "1) The distributions of **horsepower** and **enginesize** are right-skewed, which may violate the assumption of the linear model assumptions, such as linearity and homoscedasticity, and might potentially affect the model’s performance. To address this, **we will perform natural log transformation on these two features to reduce skewness** .\n",
    "\n",
    "2) The response variable price is also skewed, however, we don't usually change the output if the linear model assumptions are all met, so we will keep it unchanged by now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the distributions for these features look better.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Cleaning for Categorical Features:\n",
    "Here is the plot for categorical features:\n",
    "\n",
    "By analyzing the above class imbalance plot, the three features below have highly imbalanced class distributions.\n",
    "1) Drivewheel:\n",
    "2) Enginelocation:\n",
    "3) Cylindernumber:\n",
    "\n",
    "Such imbalance can negatively effect the model's general performance, as the model may overfit to the majority classes while underfitting the minority classes. To avoid potential problem, we have decided to **exclude** these features.\n",
    "\n",
    "---\n",
    "\n",
    "### Investigate Multicollinearity\n",
    "\n",
    "\n",
    "\n",
    "We plot the correlation matrix of the numerical features left in the data as below. \n",
    "\n",
    "\n",
    "\n",
    "<plot here\n",
    "\n",
    "\n",
    "From the correlation matrix, **horsepower** and **enginesize** are highly correlated, whcih makes sense with our intuition where the bigger enginesize usually represents the higher horsepower because they can burn more fuel and generate more power, just like \"Height\" and \"Weight\" of a child are highly correlated.\n",
    "\n",
    "\n",
    "To further investigate, we compute VIF for each feature. \n",
    "\n",
    "<plot here\n",
    "\n",
    "It seems that the VIFs for **horsepower** is near to 10 (>= 10 indicates severe multicollinearity ).\n",
    "\n",
    "So based on the above analysis, it seems to be reasonable to drop this features to reduce the risk of causing multicollinearity in our fitted model.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Fitting and Selection\n",
    "\n",
    "To select the most desirable model, we perform the best subset selection\n",
    "\n",
    "* Why best subset selection? Unlike forward/backward selection which relies on sequatial inclusion of the covariates, best subset selection evaluates all possible combinations of the covariates. This ensures that the final model is robust and not influenced by the order in which the covariates are added. \n",
    "* To address post-inference bias, we split the dataset into two subsets: a selection set and a modeling set. The best subset selection process is performed on the selection set to determine the optimal group of variables. This separation ensures that the modeling set remains independent for model evaluation. \n",
    "\n",
    "\n",
    "<plot here\n",
    "<plot here\n",
    "\n",
    "* Model with 4 covariates has the highest adjusted R^2, let's call it **Model 4**\n",
    "* Model with 6 covariates has the suitable Cp that is closest to number of (covariates+1), let's call it **Model 6**\n",
    "\n",
    "We will select the features identified in these two models and fit two multiple linear regression models—one with the three features from Model 4 and another with the four features from Model 5—using the modeling set (test split). \n",
    "\n",
    "<plot here\n",
    "\n",
    "From the table, we can see that model with 6 covariates (**Model 6**) provides the smallest RMSE and the highest adjR^2 compared to **Model 4**, so we will choose it as our final model.\n",
    "\n",
    "Now our Model Equation is: \n",
    "\n",
    "### Check Model Assumptions\n",
    "\n",
    "#### 1. Check Constant Variance Assumption\n",
    "\n",
    "<plot he\n",
    "\n",
    "The residual plot indicates a violation of the assumption of constant variance (heteroscedasticity), as the variance of residuals appears to increase with the fitted values. To address this, we will transform the output y.\n",
    "\n",
    "<summary table\n",
    "\n",
    "By observing the summary table of the fitted linear regression model, we find that the categorical variable **aspiration** is not significant, since this variable does not have interaction term with other variables and it's the addictive model\n",
    "\n",
    "\n",
    "#### 2. Check Normality of Residuals\n",
    "\n",
    "<qq plot hee\n",
    "\n",
    "The residuals are approximately normal but there are slight deviations, which suggest a heavy-tailed distribution. However, majority of the residuals closely follow the diagonal line, and also noted that we are using the test split here where it's only 30% of the original data. So this issue might be alleviated when we have more data points. \n",
    "\n",
    "\n",
    "#### 2. Check Independence of Residuals \n",
    "\n",
    "<serial corre plot here\n",
    "\n",
    "The serial correlation suggests that the sequential residual ei+1 against ei show no obvious patterns, indicating that the residuals are independent of one another. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "### Result Report and Interpretation\n",
    "Based on the final multiple linear regression model, the key findings are as follows:\n",
    "\n",
    "| Variable  | P-value               | Signicant or not   (0.05)                               |          \n",
    "|-----------|--------------------|-----------------------------------------------|\n",
    "| fueltypegas | 0.015912| Yes |\n",
    "| aspirationturbo | 0.54168 | No |\n",
    "| enginesize | 0.00114 | Yes |\n",
    "| peakrpm | 0.06011 | No\n",
    "| citympg | 1.99e-05 | Yes |\n",
    "| carlength | 0.00794 | Yes |\n",
    "\n",
    "***Note***: Logging the output in a regression model will not change the direction of the association between the original output and the input variables. However, it can change the interpretation of the coefficients.\n",
    "\n",
    "Interpretation for significant variables:\n",
    "* Fuel Type: the negative coefficient for dummy variable fueltypegas implies that gas cars are valued less than diesel cars, indicating that the price for diesel cars can be set higher.\n",
    "\n",
    "* Enginesize: the positive coefficient for enginesize points out that larger engines command higher prices, which suggests that Geely Auto can offer models with larger engine options and with higher prices.\n",
    "\n",
    "* citympg: the negative coefficient represents the fuel efficiency in miles per gallon driving in city| miles per gallo, whcih makes sense since imagine the travelling distance between a 1 million dollars car and a 10000 dollars car, the old car usually have a higher fuel efficiency but travels slower compared to the expensive cars.\n",
    "\n",
    "* carlength: the negative coefficient for the length of the car, meaning that keeping other predictors' constant, for one unit increase in the car length, the estimated natural log price of the car is decreased by 1.290e-01. This also fits the intuition since the shorter car, racing cars, the more expensive on the price. \n",
    "\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "\n",
    "The model explains a substantial portion of variance in car prices, with an adjusted R^2 of **0.8319**, which is a decent model performance.\n",
    "\n",
    "Strategies for Geely Auto:\n",
    "\n",
    "1) Diversify into Diesel-Powered Cars\n",
    "\n",
    "Geely Auto can explore the U.S. market for diesel-powered vehicles, as the analysis suggests that diesel cars command higher prices. This strategy could appeal customers who value fuel efficiency with diesel engines.\n",
    "\n",
    "2) Design Engines for different targeting Customer Segments\n",
    "\n",
    "Offer cars with a variety of engine sizes to target different customer groups. Larger engines can appeal to customers seeking higher performance, especially for cars of similar size, giving Geely Auto a competitive attribute in the U.S. market.\n",
    "\n",
    "### Caveats:\n",
    "\n",
    "1. No Interaction Terms Considered\n",
    "\n",
    "The current model doesn't consider for potential interactions between features. For example, there might be interaction between enginesize and aspiration that could influence price. Including interaction terms could provide deeper insights into how feature combinations impact pricing and improve the model performance.\n",
    "\n",
    "2. Limitations of Linear Models\n",
    "\n",
    "If we are aiming for prediction, linear model might not be enough. The linear model might not fully capture complexity and non-linear relationships between features and car prices. Exploring more complex models, such as decision trees, random forests, and kNN regression could improve predictive performance on real world data.\n",
    "\n",
    "3. Simple Metric\n",
    "\n",
    "For predictive purposes, relying on traditional metrics like adjusted R^2 might not be sufficient. Depending on the specific marketing target, different metrics should be considered. For example, RMSE and MAE, which are better for measuring model accuracy. Additionally, it will be good to implement cross-validation ensures robust evaluation of the model’s performance and reduces the risk of overfitting/underfitting to specific data subsets.\n",
    "\n",
    "4. Lack of Feature transformation and enigeering \n",
    "\n",
    "To better understand how the varaible impacts the car price, applying feature transformation is essential, such as, standardizing the numercial feature. In this way, the linear model's coefficients could be interpretable, and they will be on a comparable scale.\n",
    "\n",
    "5. Small dataset\n",
    "\n",
    "Splitting the dataset into selection and modeling sets reduces the number of data points available for fitting models. The smaller datasets may lead to overfitting to unseen data. Addressing this problem may need to leverage cross-validation or enlarge our dataset to improve model robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Appendix (Optional)\n",
    "\n",
    "Include any other relevant information or materials in this optional section. Note that the grader is not obligated to read this section, and so any content that is to be graded should be within the main body of the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
